{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30518150",
   "metadata": {},
   "source": [
    "# LOAD IMAGE AND CHECK IF SUBFOLDERS ARE BALANCED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd614a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid: 536 images\n",
      "normal: 668 images\n",
      "virus: 619 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import filters, morphology\n",
    "from scipy import ndimage\n",
    "import shutil\n",
    "\n",
    "# Define the path to the image folder\n",
    "path = 'C:/Users/user/Desktop/covid/covid_set'\n",
    "\n",
    "# Get a list of subfolders in the image folder\n",
    "subfolders = os.listdir(path)\n",
    "\n",
    "# Loop through each subfolder and print its name and the number of images it contains\n",
    "for subfolder in subfolders:\n",
    "    subdir_path = os.path.join(path, subfolder)\n",
    "    num_images = len(os.listdir(subdir_path))\n",
    "    print(f\"{subfolder}: {num_images} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6beb6a",
   "metadata": {},
   "source": [
    "# CLEAN DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a458f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import filters, morphology\n",
    "from scipy import ndimage\n",
    "\n",
    "# Define the path to the image folder\n",
    "path = 'C:/Users/user/Desktop/covid/covid_set'\n",
    "\n",
    "# Load and preprocess each image\n",
    "for filename in os.listdir(path):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
    "        filepath = os.path.join(path, filename)\n",
    "        img = cv2.imread(filepath)\n",
    "\n",
    "        # Remove artifacts and noise\n",
    "        img = cv2.medianBlur(img, 3)\n",
    "        img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "        edges = filters.sobel(img[:,:,0])\n",
    "        edges = morphology.binary_dilation(edges)\n",
    "        edges = ndimage.binary_fill_holes(edges)\n",
    "        img = np.where(edges[..., np.newaxis], img, 255)\n",
    "\n",
    "        # Normalize the image\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.equalizeHist(img)\n",
    "\n",
    "        # Crop and resize the image\n",
    "        img = img[100:400, 100:400]\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "\n",
    "        # Save the cleaned image\n",
    "        cv2.imwrite(filepath, img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4ba2f4",
   "metadata": {},
   "source": [
    "# BALANCE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f8ba01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid 536\n",
      "normal 536\n",
      "virus 536\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get a list of all the image folders in the parent folder\n",
    "folders = [os.path.join(path, folder) for folder in os.listdir(path) if os.path.isdir(os.path.join(path, folder))]\n",
    "\n",
    "# Find the smallest number of images in a folder\n",
    "min_num_images = min([len(os.listdir(folder)) for folder in folders])\n",
    "\n",
    "# Copy an equal number of images from each folder to a new folder\n",
    "new_path = 'C:/Users/user/Desktop/covid/covid_set_balanced'\n",
    "for folder in folders:\n",
    "    images = os.listdir(folder)[:min_num_images]\n",
    "    for image in images:\n",
    "        source_path = os.path.join(folder, image)\n",
    "        destination_path = os.path.join(new_path, os.path.basename(folder), image)\n",
    "        os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n",
    "        shutil.copyfile(source_path, destination_path)\n",
    "\n",
    "# Check the number of images in each folder\n",
    "for folder in os.listdir(new_path):\n",
    "    print(folder, len(os.listdir(os.path.join(new_path, folder))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f8cada",
   "metadata": {},
   "source": [
    "# EXTRACT FEATURES USING HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd3b353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1608, 15876)\n",
      "(1608,)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Define the path to the preprocessed data folder\n",
    "preprocessed_path = 'C:/Users/user/Desktop/covid/covid_set_balanced'\n",
    "\n",
    "# Define the HOG parameters\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (3, 3)\n",
    "block_norm = 'L2-Hys'\n",
    "\n",
    "# Initialize empty feature and label lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each subdirectory and extract HOG features for each image\n",
    "for label in ['covid', 'normal', 'virus']:\n",
    "    path = os.path.join(preprocessed_path, label)\n",
    "    for image_file in os.listdir(path):\n",
    "        # Load the image\n",
    "        img = cv2.imread(os.path.join(path, image_file))\n",
    "\n",
    "        # Reduce the size of the image\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "\n",
    "        # Extract HOG features\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        hog_features = hog(gray, orientations=orientations, pixels_per_cell=pixels_per_cell, \n",
    "                           cells_per_block=cells_per_block, block_norm=block_norm)\n",
    "\n",
    "        # Append the features and label to the lists\n",
    "        features.append(hog_features)\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert the feature and label lists to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Save the extracted features\n",
    "np.save('features.npy', features)\n",
    "\n",
    "# Print the shapes of the feature and label arrays\n",
    "print(features.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754a3f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc96d94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy = 0.9503105590062112\n",
      "Fold 2: Accuracy = 0.9503105590062112\n",
      "Fold 3: Accuracy = 0.937888198757764\n",
      "Fold 4: Accuracy = 0.968944099378882\n",
      "Fold 5: Accuracy = 0.9440993788819876\n",
      "Fold 6: Accuracy = 0.9627329192546584\n",
      "Fold 7: Accuracy = 0.9503105590062112\n",
      "Fold 8: Accuracy = 0.9440993788819876\n",
      "Fold 9: Accuracy = 0.975\n",
      "Fold 10: Accuracy = 0.95\n",
      "\n",
      "Average accuracy = 0.9533695652173912\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.feature import hog\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define the path to the preprocessed data folder\n",
    "preprocessed_path = 'C:/Users/user/Desktop/covid/covid_set_balanced'\n",
    "\n",
    "# Define the HOG parameters\n",
    "orientations = 9\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (3, 3)\n",
    "block_norm = 'L2-Hys'\n",
    "\n",
    "# Initialize empty feature and label lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each subdirectory and extract HOG features for each image\n",
    "for label in ['covid', 'normal', 'virus']:\n",
    "    path = os.path.join(preprocessed_path, label)\n",
    "    for image_file in os.listdir(path):\n",
    "        # Load the image\n",
    "        img = cv2.imread(os.path.join(path, image_file))\n",
    "\n",
    "        # Reduce the size of the image\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "\n",
    "        # Extract HOG features\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        hog_features = hog(gray, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, block_norm=block_norm)\n",
    "\n",
    "        # Append the features and label to the lists\n",
    "        features.append(hog_features)\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert features and labels to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Get the confusion matrix\n",
    "cm = confusion_matrix(y, y_pred) \n",
    "labels=['covid', 'normal', 'virus']\n",
    "\n",
    "# Calculate the true positives, false positives, true negatives, and false negatives\n",
    "TP = np.diag(cm)\n",
    "FP = cm.sum(axis=0) - TP\n",
    "FN = cm.sum(axis=1) - TP\n",
    "TN = cm.sum() - (TP + FP + FN)\n",
    "\n",
    "# Calculate the specificity and sensitivity\n",
    "specificity = TN / (TN + FP)\n",
    "sensitivity = TP / (TP + FN)\n",
    "\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cd41966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy = 0.9950248756218906\n",
      "F1 score = 0.9950236785024305\n",
      "Cohen's Kappa score = 0.9925373134328358\n",
      "\n",
      "Confusion Matrix:\n",
      "[[536   0   0]\n",
      " [  2 533   1]\n",
      " [  0   5 531]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier using the entire dataset and print the accuracy, f1, and cohen k scores\n",
    "y_pred = clf.predict(features)\n",
    "accuracy = metrics.accuracy_score(labels, y_pred)\n",
    "f1 = metrics.f1_score(labels, y_pred, average='weighted')\n",
    "cohen_k = metrics.cohen_kappa_score(labels, y_pred)\n",
    "print(f\"\\nAccuracy = {accuracy}\")\n",
    "print(f\"F1 score = {f1}\")\n",
    "print(f\"Cohen's Kappa score = {cohen_k}\")\n",
    "\n",
    "# Calculate and print the confusion matrix for the classifier\n",
    "confusion_matrix = metrics.confusion_matrix(labels, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73163773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: [0.99813433 0.99533582 0.99906716]\n",
      "Sensitivity: [1.         0.99440299 0.99067164]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get the confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(labels, y_pred)\n",
    "\n",
    "# Calculate the true positives, false positives, true negatives, and false negatives\n",
    "TP = np.diag(confusion_matrix)\n",
    "FP = confusion_matrix.sum(axis=0) - TP\n",
    "FN = confusion_matrix.sum(axis=1) - TP\n",
    "TN = confusion_matrix.sum() - (TP + FP + FN)\n",
    "\n",
    "# Calculate the specificity and sensitivity\n",
    "specificity = TN / (TN + FP)\n",
    "sensitivity = TP / (TP + FN)\n",
    "\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9e01db",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fc10a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Accuracy = 0.9254658222198486\n",
      "Fold 2: Accuracy = 0.8322981595993042\n",
      "Fold 3: Accuracy = 0.9689440727233887\n",
      "Fold 4: Accuracy = 0.9875776171684265\n",
      "Fold 5: Accuracy = 0.9627329111099243\n",
      "Fold 6: Accuracy = 0.9689440727233887\n",
      "Fold 7: Accuracy = 0.9937888383865356\n",
      "Fold 8: Accuracy = 0.9813664555549622\n",
      "Fold 9: Accuracy = 0.987500011920929\n",
      "Fold 10: Accuracy = 1.0\n",
      "\n",
      "Average accuracy = 0.9608617961406708\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the path to the preprocessed data folder\n",
    "preprocessed_path = 'C:/Users/user/Desktop/covid/covid_set_balanced'\n",
    "\n",
    "# Define the input shape of the images\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "# Initialize empty feature and label lists\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each subdirectory and extract the images and labels\n",
    "for label in ['covid', 'normal', 'virus']:\n",
    "    path = os.path.join(preprocessed_path, label)\n",
    "    for image_file in os.listdir(path):\n",
    "        # Load the image\n",
    "        img = cv2.imread(os.path.join(path, image_file))\n",
    "\n",
    "        # Reduce the size of the image\n",
    "        img = cv2.resize(img, (input_shape[0], input_shape[1]))\n",
    "\n",
    "        # Append the image and label to the lists\n",
    "        features.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert features and labels to numpy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode the labels as integers\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Convert labels to categorical\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "# Initialize the CNN classifier\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first convolutional layer\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "\n",
    "# Add the first pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add the second convolutional layer\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Add the second pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output of the second pooling layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add the first dense layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Initialize the StratifiedKFold cross validator\n",
    "skf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize empty lists to store the accuracy score for each fold\n",
    "accuracy_scores = []\n",
    "\n",
    "# Loop through each fold and train the classifier\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(skf.split(features, labels)):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = features[train_idx], features[test_idx]\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    # Train the classifier\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    # Evaluate the classifier on the testing set and calculate the accuracy score\n",
    "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Print the accuracy score for the current fold\n",
    "    print(f\"Fold {fold_idx+1}: Accuracy = {accuracy}\")\n",
    "\n",
    "# Print the average accuracy score across all folds\n",
    "print(f\"\\nAverage accuracy = {np.mean(accuracy_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08dbecb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 11s 179ms/step\n",
      "Accuracy: 0.9993781094527363\n",
      "F1 Score: 0.9993781089115775\n",
      "Cohen Kappa Score: 0.9990671641791045\n",
      "Confusion Matrix:\n",
      "[[535   1   0]\n",
      " [  0 536   0]\n",
      " [  0   0 536]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier on the entire dataset\n",
    "y_pred_all = np.argmax(model.predict(features), axis=1)\n",
    "y_true_all = np.argmax(labels, axis=1)\n",
    "accuracy = metrics.accuracy_score(y_true_all, y_pred_all)\n",
    "f1_score = metrics.f1_score(y_true_all, y_pred_all, average='weighted')\n",
    "cohen_k_score = metrics.cohen_kappa_score(y_true_all, y_pred_all)\n",
    "\n",
    "# Print the accuracy, f1, and cohen k scores\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1_score)\n",
    "print(\"Cohen Kappa Score:\", cohen_k_score)\n",
    "\n",
    "# Calculate and print the confusion matrix for the classifier\n",
    "confusion_matrix = metrics.confusion_matrix(y_true_all, y_pred_all)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b3a008b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: [1.         0.99906716 1.        ]\n",
      "Sensitivity: [0.99813433 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get the confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(y_true_all, y_pred_all)\n",
    "\n",
    "# Calculate the true positives, false positives, true negatives, and false negatives\n",
    "TP = np.diag(confusion_matrix)\n",
    "FP = confusion_matrix.sum(axis=0) - TP\n",
    "FN = confusion_matrix.sum(axis=1) - TP\n",
    "TN = confusion_matrix.sum() - (TP + FP + FN)\n",
    "\n",
    "# Calculate the specificity and sensitivity\n",
    "specificity = TN / (TN + FP)\n",
    "sensitivity = TP / (TP + FN)\n",
    "\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc3f9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
